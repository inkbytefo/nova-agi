# TPU v3-8 Configuration for NovaNet on Turkish C4
defaults:
  - _self_
  - dataset: c4_tr # Default, but overridable

model:
  vocab_size: 5000
  out_dim: 5000
  hidden_dim: 768
  num_layers: 12
  embedding_dim: 768

training:
  lr: 0.0003
  epochs: 10
  # TPU v3-8 has 8 cores. 
  # Batch size 128 per core => 1024 Global Batch Size.
  # This ensures high utilization.
  batch_size: 512
  max_seq_len: 2048  
  steps_per_epoch: 5000  # 5000 * 1024 = ~5M samples per epoch
  val_steps: 100
  seed: 42
  alpha: 0.0001 # Energy penalty
  beta: 0.01    # Entropy bonus

dataset:
  name: "c4_tr"
  mode: "curriculum"
  max_seq_len: 2048
  # Streaming dataset doesn't need explicit size, handled by steps_per_epoch

use_wandb: true
wandb_project: "nova-agi-turkish"
run_name: "tpu-v3-8-baseline"
checkpoint_dir: "checkpoints"
