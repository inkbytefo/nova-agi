# TPU v3-8 Configuration for NovaNet on Turkish C4
defaults:
  - _self_
  - dataset: c4_tr # Default, but overridable

model:
  hidden_dim: 512
  layers: 8
  num_heads: 8
  dropout: 0.1
  use_attention: true
  vocab_size: 32000
  embedding_dim: 512

training:
  lr: 0.0003
  epochs: 10
  # TPU v3-8 has 8 cores. 
  # Batch size 128 per core => 1024 Global Batch Size.
  # This ensures high utilization.
  batch_size: 1024  
  steps_per_epoch: 5000  # 5000 * 1024 = ~5M samples per epoch
  val_steps: 100
  seed: 42
  alpha: 0.0001 # Energy penalty
  beta: 0.01    # Entropy bonus

dataset:
  name: "c4_tr"
  mode: "curriculum"
  max_seq_len: 128
  # Streaming dataset doesn't need explicit size, handled by steps_per_epoch

use_wandb: true
wandb_project: "nova-agi-turkish"
run_name: "tpu-v3-8-baseline"
checkpoint_dir: "checkpoints"
