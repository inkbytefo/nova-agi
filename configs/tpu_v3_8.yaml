# TPU v3-8 Configuration for NovaNet on Turkish C4
model:
  hidden_dim: 512
  num_layers: 8
  num_heads: 8
  out_dim: 32000     # Matches vocab_size
  dropout_rate: 0.1
  use_attention: true
  vocab_size: 32000
  embedding_dim: 512

training:
  lr: 0.0003
  epochs: 10
  # TPU v3-8 has 8 cores. 
  # Batch size 128 per core => 1024 Global Batch Size.
  # This ensures high utilization.
  batch_size: 1024  
  steps_per_epoch: 5000  # 5000 * 1024 = ~5M samples per epoch
  val_steps: 100
  seed: 42
  alpha: 0.0001 # Energy penalty
  beta: 0.01    # Entropy bonus

dataset:
  name: "c4_tr"
  # Streaming dataset doesn't need explicit size, handled by steps_per_epoch

use_wandb: true
wandb_project: "nova-agi-turkish"
run_name: "tpu-v3-8-baseline"
checkpoint_dir: "checkpoints"
